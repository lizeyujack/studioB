{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Sunil tweeted,\"Witnessing 70th Republic Day of India from Rajpath,\\\n",
    "New Delhi. Mesmerizing performance by Indian Army! Awesome airshow! @india_official\\\n",
    "@indian_army #India #70thRepublic_Day. For more photos ping me sunil@photoking.com :)\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " 'Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " 'New',\n",
       " 'Delhi',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " 'india',\n",
       " 'official',\n",
       " 'indian',\n",
       " 'army',\n",
       " 'India',\n",
       " '70thRepublic',\n",
       " 'Day',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil',\n",
       " 'photoking',\n",
       " 'com']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'([^\\s\\w]|_)+',' ',sentence).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def n_gram_extractor(sentence,n):\n",
    "    tokens = re.sub(r'([^\\s\\w]|_)+',' ',sentence).split()\n",
    "    for i in range(len(tokens)-n+1):\n",
    "        print(tokens[i:i+n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cute']\n",
      "['cute', 'little']\n",
      "['little', 'boy']\n",
      "['boy', 'is']\n",
      "['is', 'playing']\n",
      "['playing', 'with']\n",
      "['with', 'the']\n",
      "['the', 'kitten']\n"
     ]
    }
   ],
   "source": [
    "## Bi-gram\n",
    "n_gram_extractor('The cute little boy is playing with the kitten.',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cute', 'little']\n",
      "['cute', 'little', 'boy']\n",
      "['little', 'boy', 'is']\n",
      "['boy', 'is', 'playing']\n",
      "['is', 'playing', 'with']\n",
      "['playing', 'with', 'the']\n",
      "['with', 'the', 'kitten']\n"
     ]
    }
   ],
   "source": [
    "## Tri-grams\n",
    "n_gram_extractor('The cute little boy is playing with the kitten.',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'cute'),\n",
       " ('cute', 'little'),\n",
       " ('little', 'boy'),\n",
       " ('boy', 'is'),\n",
       " ('is', 'playing'),\n",
       " ('playing', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'kitten.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "list(ngrams('The cute little boy is playing with the kitten.'.split(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'cute', 'little'),\n",
       " ('cute', 'little', 'boy'),\n",
       " ('little', 'boy', 'is'),\n",
       " ('boy', 'is', 'playing'),\n",
       " ('is', 'playing', 'with'),\n",
       " ('playing', 'with', 'the'),\n",
       " ('with', 'the', 'kitten.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams('The cute little boy is playing with the kitten.'.split(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['The', 'cute']),\n",
       " WordList(['cute', 'little']),\n",
       " WordList(['little', 'boy']),\n",
       " WordList(['boy', 'is']),\n",
       " WordList(['is', 'playing']),\n",
       " WordList(['playing', 'witht']),\n",
       " WordList(['witht', 'the']),\n",
       " WordList(['the', 'kitten'])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"The cute little boy is playing witht the kitten\")\n",
    "blob.ngrams(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['The', 'cute', 'little']),\n",
       " WordList(['cute', 'little', 'boy']),\n",
       " WordList(['little', 'boy', 'is']),\n",
       " WordList(['boy', 'is', 'playing']),\n",
       " WordList(['is', 'playing', 'witht']),\n",
       " WordList(['playing', 'witht', 'the']),\n",
       " WordList(['witht', 'the', 'kitten'])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Sunil tweeted, \"Witnessing 70th Republic Day of India from Rajpath, \\\n",
    "New Delhi. Mesmerizing performance by Indian Army! Awesome airshow! @india_official \\\n",
    "@indian_army #India #70thRepublic_Day. For more photos ping me sunil@photoking.com :)\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sunil',\n",
       " 'tweeted',\n",
       " 'witnessing',\n",
       " '70th',\n",
       " 'republic',\n",
       " 'day',\n",
       " 'of',\n",
       " 'india',\n",
       " 'from',\n",
       " 'rajpath',\n",
       " 'new',\n",
       " 'delhi',\n",
       " 'mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'indian',\n",
       " 'army',\n",
       " 'awesome',\n",
       " 'airshow',\n",
       " 'india',\n",
       " 'official',\n",
       " 'indian',\n",
       " 'army',\n",
       " 'india',\n",
       " '70threpublic',\n",
       " 'day',\n",
       " 'for',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil',\n",
       " 'photoking',\n",
       " 'com']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_word_sequence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Sunil', 'tweeted', 'Witnessing', '70th', 'Republic', 'Day', 'of', 'India', 'from', 'Rajpath', 'New', 'Delhi', 'Mesmerizing', 'performance', 'by', 'Indian', 'Army', 'Awesome', 'airshow', 'india_official', 'indian_army', 'India', '70thRepublic_Day', 'For', 'more', 'photos', 'ping', 'me', 'sunil', 'photoking.com'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(sentence)\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Sunil tweeted, \"Witnessing 70th Republic Day of India from Rajpath, \\\n",
    "New Delhi. Mesmerizing performance by Indian Army! Awesome airshow! @india_official \\\n",
    "@indian_army #India #70thRepublic_Day. For more photos ping me sunil@photoking.com :)\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " ',',\n",
       " '\"',\n",
       " 'Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " ',',\n",
       " 'New',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " '!',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day',\n",
       " '.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " ':)',\n",
       " '\"']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "tweet_tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MWE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted,',\n",
       " '\"Witnessing',\n",
       " '70th',\n",
       " 'Republic_Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath,',\n",
       " 'New',\n",
       " 'Delhi.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army!',\n",
       " 'Awesome',\n",
       " 'airshow!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "mwe_tokenizer = MWETokenizer([('Republic','Day')])\n",
    "mwe_tokenizer.add_mwe(('Indian','Amy'))\n",
    "mwe_tokenizer.tokenize(sentence.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regular expression tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " ',',\n",
       " '\"Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " ',',\n",
       " 'New',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " '!',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil',\n",
       " '@photoking.com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "reg_tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "reg_tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## whitespace Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted,',\n",
       " '\"Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath,',\n",
       " 'New',\n",
       " 'Delhi.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army!',\n",
       " 'Awesome',\n",
       " 'airshow!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "wh_tokenizer = WhitespaceTokenizer()\n",
    "wh_tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word punkt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " ',',\n",
       " '\"',\n",
       " 'Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " ',',\n",
       " 'New',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " '!',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '!',\n",
       " '@',\n",
       " 'india_official',\n",
       " '@',\n",
       " 'indian_army',\n",
       " '#',\n",
       " 'India',\n",
       " '#',\n",
       " '70thRepublic_Day',\n",
       " '.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil',\n",
       " '@',\n",
       " 'photoking',\n",
       " '.',\n",
       " 'com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "wp_tokenizer = WordPunctTokenizer()\n",
    "wp_tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I love playing football\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love play football'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "regex_stemmer = RegexpStemmer('ing$',min=4)\n",
    "' '.join([regex_stemmer.stem(wd) for wd in sentence.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Before eating,it would be nice to sanitize your hands with a sanitizer\"\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'befor eating,it would be nice to sanit your hand with a sanit'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_stemmer = PorterStemmer()\n",
    "' '.join([ps_stemmer.stem(wd) for wd in sentence.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lizey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sentence = \"The products produced by the process today are far better than what it produces generally\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The product produced by the process today are far better than what it produce generally'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(sentence)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singularizing and Pluralizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "sentence = TextBlob('She sells seashells on the seashore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['She', 'sells', 'seashells', 'on', 'the', 'seashore'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sell'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[1].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seashores'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[5].pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"你好！李泽宇\")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_blob = TextBlob('hello! zeyu li')\n",
    "en_blob.translate(from_lang='en',to = 'zh-CN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP-WORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "sentence = \"She sells seashells on the seashore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sells seashells seashore'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_stop_word_list = ['she','on','the','am','is','not']\n",
    "' '.join([word for word in word_tokenize(sentence) if word.lower() not in custom_stop_word_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACTING GENERAL FEATURES FROM RAW TEXTFeature Extraction from Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The interim budget for 2019 will be announced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you know how much expectation the middle-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>February is the shortest month in a year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This financial year will end on 31st March.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  The interim budget for 2019 will be announced ...\n",
       "1  Do you know how much expectation the middle-cl...\n",
       "2          February is the shortest month in a year.\n",
       "3        This financial year will end on 31st March."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([['The interim budget for 2019 will be announced on 1st February.'], ['Do you know how much expectation the middle-class working population is having from this budget?'], ['February is the shortest month in a year.'], ['This financial year will end on 31st March.']])\n",
    "df.columns = ['text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "1    15\n",
       "2     8\n",
       "3     8\n",
       "Name: number_of_words, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count words\n",
    "from textblob import TextBlob\n",
    "df['number_of_words'] = df['text'].apply(lambda x : len(TextBlob(str(x)).words))\n",
    "df['number_of_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence contain wh-\n",
    "wh_words = set(['why', 'who', 'which', 'what', 'where', 'when', 'how'])\n",
    "df['is_wh_words_present'] = df['text'].apply(lambda x : True if\\\n",
    "                                            len(set(TextBlob(str(x)).words).intersection(wh_words))>0\n",
    "                                            else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "Name: is_wh_words_present, dtype: bool"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_wh_words_present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.2\n",
       "2    0.0\n",
       "3    0.0\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract their sentiment scores:\n",
    "df['polarity'] = df['text'].apply(lambda x : TextBlob(str(x)).sentiment.polarity)\n",
    "df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.2\n",
       "2    0.0\n",
       "3    0.0\n",
       "Name: subjectivity, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract their subjectivity scores:\n",
    "df['subjectivity'] = df['text'].apply(lambda x :TextBlob(str(x)).sentiment.subjectivity)\n",
    "df['subjectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    en\n",
       "1    en\n",
       "2    en\n",
       "3    en\n",
       "Name: language, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language']=df['text'].apply(lambda x :\n",
    "                               TextBlob(str(x)).detect_language())\n",
    "df['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>is_wh_words_present</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The interim budget for 2019 will be announced ...</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you know how much expectation the middle-cl...</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>February is the shortest month in a year.</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This financial year will end on 31st March.</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  number_of_words  \\\n",
       "0  The interim budget for 2019 will be announced ...               11   \n",
       "1  Do you know how much expectation the middle-cl...               15   \n",
       "2          February is the shortest month in a year.                8   \n",
       "3        This financial year will end on 31st March.                8   \n",
       "\n",
       "   is_wh_words_present  polarity  subjectivity language  \n",
       "0                False       0.0           0.0       en  \n",
       "1                 True       0.2           0.2       en  \n",
       "2                False       0.0           0.0       en  \n",
       "3                False       0.0           0.0       en  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACTING GENERAL FEATURES FROM TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      23\n",
       "1      21\n",
       "2      36\n",
       "3      18\n",
       "4      15\n",
       "5      20\n",
       "6      52\n",
       "7      83\n",
       "8      63\n",
       "9      54\n",
       "10     90\n",
       "11     71\n",
       "12     67\n",
       "13    129\n",
       "14     92\n",
       "Name: number_letters, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['number_letters'] = data['text'].apply(lambda x:\n",
    "                                          len(TextBlob(str(x))))\n",
    "data['number_letters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      23\n",
       "1      21\n",
       "2      36\n",
       "3      18\n",
       "4      15\n",
       "5      20\n",
       "6      52\n",
       "7      83\n",
       "8      63\n",
       "9      54\n",
       "10     90\n",
       "11     71\n",
       "12     67\n",
       "13    129\n",
       "14     92\n",
       "Name: number_letters, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
