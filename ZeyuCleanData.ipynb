{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda_files\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_number</th>\n",
       "      <th>affected_service</th>\n",
       "      <th>priority</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13133</td>\n",
       "      <td>Other</td>\n",
       "      <td>Minor</td>\n",
       "      <td>NTD ODU red. Rebooted in isolation, Still red....</td>\n",
       "      <td>NWAS-OTHER-*ANOM_ID36945*-ANOM_ID5775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17314</td>\n",
       "      <td>Intermittent signal</td>\n",
       "      <td>Minor</td>\n",
       "      <td>EU is reporting slow internet connection.\\r\\nP...</td>\n",
       "      <td>NWAS - Dropouts -*ANOM_ID42107*- ANOM_ID14570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17281</td>\n",
       "      <td>Loss of Signal</td>\n",
       "      <td>Minor</td>\n",
       "      <td>ISSUE:  Red ODU\\r\\n\\r\\nService Address:|Addres...</td>\n",
       "      <td>NWAS -*ANOM_ID5433*-*ANOM_ID13853*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3252</td>\n",
       "      <td>Intermittent signal</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Fault Symptom: Drop Outs\\r\\n\\r\\nHave you check...</td>\n",
       "      <td>NWAS || Intermittent || ANOM_ID47835 || -*ANOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10699</td>\n",
       "      <td>Loss of Signal</td>\n",
       "      <td>Minor</td>\n",
       "      <td>EU is unable to connect to the internet.\\r\\nPr...</td>\n",
       "      <td>NWAS||SERVICE LOSS||`ICE LOSS||-*ANOM_ID58216*...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_number     affected_service priority  \\\n",
       "0       13133                Other    Minor   \n",
       "1       17314  Intermittent signal    Minor   \n",
       "2       17281       Loss of Signal    Minor   \n",
       "3        3252  Intermittent signal   Medium   \n",
       "4       10699       Loss of Signal    Minor   \n",
       "\n",
       "                                         description  \\\n",
       "0  NTD ODU red. Rebooted in isolation, Still red....   \n",
       "1  EU is reporting slow internet connection.\\r\\nP...   \n",
       "2  ISSUE:  Red ODU\\r\\n\\r\\nService Address:|Addres...   \n",
       "3  Fault Symptom: Drop Outs\\r\\n\\r\\nHave you check...   \n",
       "4  EU is unable to connect to the internet.\\r\\nPr...   \n",
       "\n",
       "                                               title  \n",
       "0              NWAS-OTHER-*ANOM_ID36945*-ANOM_ID5775  \n",
       "1      NWAS - Dropouts -*ANOM_ID42107*- ANOM_ID14570  \n",
       "2                 NWAS -*ANOM_ID5433*-*ANOM_ID13853*  \n",
       "3  NWAS || Intermittent || ANOM_ID47835 || -*ANOM...  \n",
       "4  NWAS||SERVICE LOSS||`ICE LOSS||-*ANOM_ID58216*...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('UTS_TT_DATA.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'Intermittent signal', 'Loss of Signal', 'Dead UNI-D',\n",
       "       'Signal degradation', 'Dead WNTD', 'Physical damage',\n",
       "       'Packet Loss', 'Dead UNI-V', 'Power Supply Unit',\n",
       "       'Intermittent Power', nan, 'No dataflow', 'Slow speed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.affected_service.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument must be a string or number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda_files\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_files\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c154daca68a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlbl_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlbl_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffected_service\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda_files\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \"\"\"\n\u001b[0;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_files\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"argument must be a string or number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument must be a string or number"
     ]
    }
   ],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.affected_service.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['normizateddescription'] = data['description'].apply(lambda i:nltk.word_tokenize(text=i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EU is reporting slow internet connection.\\r\\nProvisioning between NBN and Optus has been checked and no issues found.\\r\\nOptus systems are showing no sync.\\r\\nEU has reported visible no damage to NBN equipment.\\r\\nEU has replaced Ethernet cable between WNTD and RG.\\r\\nEU has tested using an Ethernet device connected directly to the WNTD and experienced fault.\\r\\n\\r\\nPlease investigate.\\r\\n\\r\\nOpen orders - none\\r\\n\\r\\nFault Type - Intermittent service/dropouts\\r\\n\\r\\n##DIAGNOSTIC QUESTIONS##\\r\\nHas an isolation test been run? - Yes\\r\\nAny active incidents at time of fault? - No\\r\\nPower Status - Answer not provided\\r\\nPower Behaviour - Answer not provided\\r\\nLED Status - Answer not provided\\r\\nLED Behaviour - Answer not provided\\r\\nODU Status - Answer not provided\\r\\nODU Behaviour - Answer not provided\\r\\nUNI-D Status - Answer not provided\\r\\nUNI-D Behaviour - Answer not provided\\r\\nSignal Strengths Status - Answer not provided\\r\\nPorts being used - Answer not provided\\r\\nNTD Serial Number - Answer not provided\\r\\nWhat CPE Is Connected? - Answer not provided\\r\\nWhat is the CPE MAC address? - Answer not provided\\r\\nHas the CPE been powercycled? - Answer not provided\\r\\nHas an alternate CPE been tested? - Answer not provided\\r\\n\\r\\n##TEST RESULTS##\\r\\n#TEST RESULT# :1\\r\\nTest ID - ANOM_ID57221\\r\\nTest Type - Loopback test\\r\\nTest Result - Passed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU',\n",
       " 'is',\n",
       " 'reporting',\n",
       " 'slow',\n",
       " 'internet',\n",
       " 'connection',\n",
       " '.',\n",
       " 'Provisioning',\n",
       " 'between',\n",
       " 'NBN',\n",
       " 'and',\n",
       " 'Optus',\n",
       " 'has',\n",
       " 'been',\n",
       " 'checked',\n",
       " 'and',\n",
       " 'no',\n",
       " 'issues',\n",
       " 'found',\n",
       " '.',\n",
       " 'Optus',\n",
       " 'systems',\n",
       " 'are',\n",
       " 'showing',\n",
       " 'no',\n",
       " 'sync',\n",
       " '.',\n",
       " 'EU',\n",
       " 'has',\n",
       " 'reported',\n",
       " 'visible',\n",
       " 'no',\n",
       " 'damage',\n",
       " 'to',\n",
       " 'NBN',\n",
       " 'equipment',\n",
       " '.',\n",
       " 'EU',\n",
       " 'has',\n",
       " 'replaced',\n",
       " 'Ethernet',\n",
       " 'cable',\n",
       " 'between',\n",
       " 'WNTD',\n",
       " 'and',\n",
       " 'RG',\n",
       " '.',\n",
       " 'EU',\n",
       " 'has',\n",
       " 'tested',\n",
       " 'using',\n",
       " 'an',\n",
       " 'Ethernet',\n",
       " 'device',\n",
       " 'connected',\n",
       " 'directly',\n",
       " 'to',\n",
       " 'the',\n",
       " 'WNTD',\n",
       " 'and',\n",
       " 'experienced',\n",
       " 'fault',\n",
       " '.',\n",
       " 'Please',\n",
       " 'investigate',\n",
       " '.',\n",
       " 'Open',\n",
       " 'orders',\n",
       " '-',\n",
       " 'none',\n",
       " 'Fault',\n",
       " 'Type',\n",
       " '-',\n",
       " 'Intermittent',\n",
       " 'service/dropouts',\n",
       " '#',\n",
       " '#',\n",
       " 'DIAGNOSTIC',\n",
       " 'QUESTIONS',\n",
       " '#',\n",
       " '#',\n",
       " 'Has',\n",
       " 'an',\n",
       " 'isolation',\n",
       " 'test',\n",
       " 'been',\n",
       " 'run',\n",
       " '?',\n",
       " '-',\n",
       " 'Yes',\n",
       " 'Any',\n",
       " 'active',\n",
       " 'incidents',\n",
       " 'at',\n",
       " 'time',\n",
       " 'of',\n",
       " 'fault',\n",
       " '?',\n",
       " '-',\n",
       " 'No',\n",
       " 'Power',\n",
       " 'Status',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'Power',\n",
       " 'Behaviour',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'LED',\n",
       " 'Status',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'LED',\n",
       " 'Behaviour',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'ODU',\n",
       " 'Status',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'ODU',\n",
       " 'Behaviour',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'UNI-D',\n",
       " 'Status',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'UNI-D',\n",
       " 'Behaviour',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'Signal',\n",
       " 'Strengths',\n",
       " 'Status',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'Ports',\n",
       " 'being',\n",
       " 'used',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'NTD',\n",
       " 'Serial',\n",
       " 'Number',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'What',\n",
       " 'CPE',\n",
       " 'Is',\n",
       " 'Connected',\n",
       " '?',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'What',\n",
       " 'is',\n",
       " 'the',\n",
       " 'CPE',\n",
       " 'MAC',\n",
       " 'address',\n",
       " '?',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'Has',\n",
       " 'the',\n",
       " 'CPE',\n",
       " 'been',\n",
       " 'powercycled',\n",
       " '?',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " 'Has',\n",
       " 'an',\n",
       " 'alternate',\n",
       " 'CPE',\n",
       " 'been',\n",
       " 'tested',\n",
       " '?',\n",
       " '-',\n",
       " 'Answer',\n",
       " 'not',\n",
       " 'provided',\n",
       " '#',\n",
       " '#',\n",
       " 'TEST',\n",
       " 'RESULTS',\n",
       " '#',\n",
       " '#',\n",
       " '#',\n",
       " 'TEST',\n",
       " 'RESULT',\n",
       " '#',\n",
       " ':1',\n",
       " 'Test',\n",
       " 'ID',\n",
       " '-',\n",
       " 'ANOM_ID57221',\n",
       " 'Test',\n",
       " 'Type',\n",
       " '-',\n",
       " 'Loopback',\n",
       " 'test',\n",
       " 'Test',\n",
       " 'Result',\n",
       " '-',\n",
       " 'Passed']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['normizateddescription'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset = [\"affected_service\"], inplace=True)\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.affected_service.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(data.normizateddescription.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17950,)\n",
      "(1995,)\n"
     ]
    }
   ],
   "source": [
    "print (xtrain.shape)\n",
    "print (xvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### very first model: TF-IDF(Term Frequency - Inverse Document Frequency)+LR(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-b9ac626e6121>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Fitting TF-IDF to both training and test sets (semi-supervised learning)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtfv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mxtrain_tfv\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtfv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mxvalid_tfv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'Intermittent signal', 'Loss of Signal', 'Dead UNI-D',\n",
       "       'Signal degradation', 'Dead WNTD', 'Physical damage',\n",
       "       'Packet Loss', 'Dead UNI-V', 'Power Supply Unit',\n",
       "       'Intermittent Power', nan, 'No dataflow', 'Slow speed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.affected_service.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
